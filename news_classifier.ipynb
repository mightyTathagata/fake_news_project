{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "type": "CODE"
        },
        "id": "ebxJP-Ys3iUP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "type": "CODE"
        },
        "id": "GlenlMOz3iUR"
      },
      "outputs": [],
      "source": [
        "# Load the Dataset\n",
        "\n",
        "train_stances = pd.read_csv(\"https://raw.githubusercontent.com/mightyTathagata/fake_news_project/main/fnc_dataset/train_stances.csv\") #headlines\n",
        "train_bodies = pd.read_csv(\"https://raw.githubusercontent.com/mightyTathagata/fake_news_project/main/fnc_dataset/train_bodies.csv\") #body\n",
        "test_stances = pd.read_csv(\"https://raw.githubusercontent.com/mightyTathagata/fake_news_project/main/fnc_dataset/test_stances.csv\")\n",
        "test_bodies = pd.read_csv(\"https://raw.githubusercontent.com/mightyTathagata/fake_news_project/main/fnc_dataset/test_bodies.csv\")\n",
        "\n",
        "# Inner Join on the Body ID\n",
        "merged_train_data = pd.merge(train_stances, train_bodies, on=\"Body ID\")\n",
        "merged_test_data = pd.merge(test_stances, test_bodies, on=\"Body ID\")\n",
        "\n",
        "# Shuffle the Dataset\n",
        "merged_train_data = merged_train_data.sample(frac=0.3)\n",
        "merged_test_data = merged_test_data.sample(frac=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "type": "CODE"
        },
        "id": "M17WjNHj3iUR"
      },
      "outputs": [],
      "source": [
        "# Feature Label Split\n",
        "\n",
        "y_train = merged_train_data['Stance']\n",
        "x_train = merged_train_data.drop('Stance', axis=1)\n",
        "y_test = merged_test_data['Stance']\n",
        "x_test = merged_test_data.drop('Stance', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "type": "CODE"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBlbJj0N3iUS",
        "outputId": "ed1e3868-3ec0-45fa-e7ab-3ef83888bc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14992 14992\n",
            "7624 7624\n"
          ]
        }
      ],
      "source": [
        "# Train Test Split\n",
        "\n",
        "#x_train = x[:int(0.8 * len(x))]\n",
        "#x_test = x[int(0.8 * len(x)):]\n",
        "#y_train =  y[:int(0.8 * len(x))]\n",
        "#y_test = y[int(0.8 * len(x)):]\n",
        "\n",
        "print(len(x_train), len(y_train))\n",
        "print(len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "type": "CODE"
        },
        "id": "meRdvoLs3iUT"
      },
      "outputs": [],
      "source": [
        "# Declaring the function\n",
        "def process_text(text):\n",
        "\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove some punctuations\n",
        "    text = re.sub(r\"[!?,'\\\"*)@#%(&$_.^-]\", '', text)\n",
        "\n",
        "    # Splitting on spaces\n",
        "    text = text.split(' ')\n",
        "\n",
        "    # Stemming and removing spaces\n",
        "    stemmer_ps = nltk.stem.PorterStemmer()  \n",
        "    text = [stemmer_ps.stem(word) for word in text if len(word)]\n",
        "\n",
        "    return \" \".join(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming Headlines\n",
        "x_train['Headline'] = x_train['Headline'].apply(process_text)\n",
        "x_test['Headline'] = x_test['Headline'].apply(process_text)\n",
        "\n",
        "# Transforming Body\n",
        "x_train['articleBody'] = x_train['articleBody'].apply(process_text)\n",
        "x_test['articleBody'] = x_test['articleBody'].apply(process_text)"
      ],
      "metadata": {
        "id": "r9KF18Hj-QcG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yA1KqlLv3iUU"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "tfv_headline = TfidfVectorizer(max_features=2500)\n",
        "\n",
        "tfv_headline.fit((x_train['Headline']))\n",
        "xtrain_tfv_headline =  tfv_headline.transform(x_train['Headline'])\n",
        "\n",
        "\n",
        "xtest_tfv_headline =  tfv_headline.transform(x_test['Headline'])\n",
        "\n",
        "tfv_body = TfidfVectorizer(max_features=2500)\n",
        "\n",
        "tfv_body.fit((x_train['articleBody']))\n",
        "xtrain_tfv_body =  tfv_body.transform(x_train['articleBody'])\n",
        "\n",
        "xtest_tfv_body =  tfv_body.transform(x_test['articleBody'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain_tfv_headline.shape)\n",
        "print(xtest_tfv_headline.shape)\n",
        "print(xtrain_tfv_body.shape)\n",
        "print(xtest_tfv_body.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeFe5HUY8ooS",
        "outputId": "cf725d65-b5b1-4013-efd5-73925cec25c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14992, 2500)\n",
            "(7624, 2500)\n",
            "(14992, 2500)\n",
            "(7624, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "xtrain_tfv = hstack([xtrain_tfv_headline, xtrain_tfv_body]).toarray()\n",
        "\n",
        "xtest_tfv = hstack([xtest_tfv_headline, xtest_tfv_body]).toarray()\n"
      ],
      "metadata": {
        "id": "6-sLl8CPGWMy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ADxxNe9X3iUV"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_tfv, y_train)\n",
        "predictions = clf.predict(xtest_tfv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, predictions, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGxHGBZ4HBy1",
        "outputId": "c26e5860-f412-4629-eff9-ce3257681b9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6104640322636589"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing, decomposition\n",
        "\n",
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xtest_svd = svd.transform(xtest_tfv)\n",
        "\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_scl = scl.transform(xtrain_svd)\n",
        "xtest_scl = scl.transform(xtest_svd)\n",
        "\n",
        "\n",
        "clf = SVC(C=1.0, probability=True)\n",
        "clf.fit(xtrain_scl, y_train)\n",
        "predictions_svm = clf.predict(xtest_scl)\n",
        "\n",
        "f1_score(y_test, predictions_svm, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyn2vcl-RHzS",
        "outputId": "66e3e2ea-ed13-4e65-8833-609dd923bbc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6723799876315201"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
        "clf.fit(xtrain_tfv, y_train)\n",
        "predictions_rf = clf.predict(xtest_tfv)\n"
      ],
      "metadata": {
        "id": "jRmMDyhGYFFI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test, predictions_rf, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlzP6lfcY1tb",
        "outputId": "6ba13c1e-453d-4991-ec0a-e51f1f62b241"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6084206858799869"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "datalore": {
      "base_environment": "default",
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "packages": [
        {
          "name": "nltk",
          "source": "PIP",
          "version": "3.7"
        }
      ],
      "version": 1
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "news_classifier.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}